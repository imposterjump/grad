import fs from 'fs';
import { execSync } from 'child_process';
import ffmpeg from 'fluent-ffmpeg';

// Path to eSpeak executable
const ESPEAK_PATH = "C:/espeak/command_line/espeak.exe";

// **1Ô∏è‚É£ Function to Extract Audio Duration**
function getAudioDuration(audioPath) {
    return new Promise((resolve, reject) => {
        ffmpeg.ffprobe(audioPath, (err, metadata) => {
            if (err) {
                console.error("‚ùå Error getting audio duration:", err);
                reject(err);
            } else {
                const duration = metadata.format.duration;
                console.log(`üéµ Audio Duration: ${duration.toFixed(2)} seconds`);
                resolve(duration);
            }
        });
    });
}

// **2Ô∏è‚É£ Function to Get Cleaned Phonemes**
function getPhonemes(sentence) {
    try {
        const command = `${ESPEAK_PATH} -q --ipa=3 "${sentence}"`;
        let output = execSync(command, { encoding: 'utf-8' }).trim();

        console.log(`üîµ Raw Phoneme Output:`, output);

        // **üîÑ Step 1: Cleanup output (remove weird symbols)**
        let phonemeArray = output
            .replace(/[_ÀàÀå]/g, " ") // Remove underscores & stress markers
            .replace(/\s+/g, " ") // Remove extra spaces
            .trim()
            .split(" "); // Properly split phonemes

        console.log("üìå Cleaned Phoneme Array:", phonemeArray);
        return phonemeArray;
    } catch (error) {
        console.error("‚ùå Error generating phonemes:", error);
        return [];
    }
}

// **3Ô∏è‚É£ Generalized Phoneme-to-Viseme Mapping**
const phonemeToViseme = {
    "p": "B",
    "b": "B",
    "m": "B", // Closed lips
    "f": "E",
    "v": "E", // Top teeth on bottom lip
    "Œ∏": "C",
    "√∞": "C", // Tongue between teeth
    "t": "D",
    "d": "D",
    "s": "D",
    "z": "D",
    "n": "D",
    "l": "D",
    "r": "D", // Tongue touches roof
    " É": "F",
    " í": "F",
    "t É": "F",
    "d í": "F", // "sh", "ch" sounds
    "k": "G",
    "g": "G",
    "≈ã": "G", // Back of tongue lifts
    "h": "X", // Neutral / silent
    "e…™": "A",
    "a…™": "A",
    "…î…™": "A",
    "o ä": "A",
    "ju": "A", // "ey", "ai", "oy"
    "√¶": "B",
    "…õ": "B",
    "e": "B", // Mid-open mouth
    "i": "C",
    "…™": "C", // Smile (like "ee")
    " ä": "B",
    "u": "B", // Rounded lips
    " å": "D",
    "…ë": "D",
    "…í": "D", // Open mouth vowels
    "…î": "F",
    "a ä": "F", // "aw" sounds
    "j": "C",
    "w": "C", // Semi-vowels
    "≈ã": "X" // Nasal closure
};

// **4Ô∏è‚É£ Function to Map Phonemes to Visemes**
function mapPhonemesToVisemes(phonemes) {
    return phonemes.map(phoneme => {
        let mappedValue = phonemeToViseme[phoneme] || "X"; // Default to "X"
        console.log(`üîÑ Mapping: "${phoneme}" ‚Üí "${mappedValue}"`);
        return { value: mappedValue };
    });
}

// **5Ô∏è‚É£ Function to Generate LipSync JSON**
async function generateLipSyncJSON(sentence, audioPath, savePath) {
    try {
        const duration = await getAudioDuration(audioPath);
        const rawPhonemes = getPhonemes(sentence);
        const mappedMouthCues = mapPhonemesToVisemes(rawPhonemes);

        if (mappedMouthCues.length === 0) {
            console.error("‚ùå No mouth cues generated. Exiting.");
            return;
        }

        const interval = duration / mappedMouthCues.length;

        // **Generate Timestamped Mouth Cues**
        const mouthCues = mappedMouthCues.map((cue, index) => ({
            start: parseFloat((index * interval).toFixed(2)),
            end: parseFloat(((index + 1) * interval).toFixed(2)),
            value: cue.value
        }));

        const data = {
            metadata: { duration: parseFloat(duration.toFixed(2)) },
            mouthCues
        };

        fs.writeFileSync(savePath, JSON.stringify(data, null, 4));
        console.log(`‚úÖ LipSync JSON saved to ${savePath}`);
    } catch (error) {
        console.error("‚ùå Error in LipSync Generation:", error);
    }
}

// **üöÄ Run Example**
const sentence = "Hey dear, how was your day";
const audioPath = "C:/new grad project (farid version)/grad/backend/audios/intro_0.wav";
const savePath = "C:/new grad project (farid version)/grad/backend/audios/lipsync_intro_1.json";

generateLipSyncJSON(sentence, audioPath, savePath);